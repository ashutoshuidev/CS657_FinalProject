{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession, SQLContext, Row\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import explode, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-678c8718447f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-678c8718447f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def makePairs((user, ratings)):\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def makePairs((user, ratings)):\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return ((movie1, movie2), (rating1, rating2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDuplicates( (userID, ratings) ):\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return movie1 < movie2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Similarity for each pair of items and predict the scores\n",
    "# instead of passing rating pairs pass\n",
    "def computeCosineSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    # change the loops - loop over all the rating pairs\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        numPairs += 1\n",
    "\n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "\n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    "\n",
    "    return (score, numPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|      2|   3.5|1112486027|\n",
      "|     1|     29|   3.5|1112484676|\n",
      "|     1|     32|   3.5|1112484819|\n",
      "|     1|     47|   3.5|1112484727|\n",
      "|     1|     50|   3.5|1112484580|\n",
      "|     1|    112|   3.5|1094785740|\n",
      "|     1|    151|   4.0|1094785734|\n",
      "|     1|    223|   4.0|1112485573|\n",
      "|     1|    253|   4.0|1112484940|\n",
      "|     1|    260|   4.0|1112484826|\n",
      "|     1|    293|   4.0|1112484703|\n",
      "|     1|    296|   4.0|1112484767|\n",
      "|     1|    318|   4.0|1112484798|\n",
      "|     1|    337|   3.5|1094785709|\n",
      "|     1|    367|   3.5|1112485980|\n",
      "|     1|    541|   4.0|1112484603|\n",
      "|     1|    589|   3.5|1112485557|\n",
      "|     1|    593|   3.5|1112484661|\n",
      "|     1|    653|   3.0|1094785691|\n",
      "|     1|    919|   3.5|1094785621|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SparkSession' object has no attribute 'textFile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b4eccc22f98b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m# Map ratings to key / value pairs: user ID => movie ID, rating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/My_Data/MS/CS657/HW-4/InputData/ratings.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[1;31m# print(data.collect())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"::\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SparkSession' object has no attribute 'textFile'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create a SparkSession (Note, the config section is only for Windows!)\n",
    "    spark = SparkSession.builder.appName(\"RecommenderSystem\").getOrCreate()\n",
    "\n",
    "    \n",
    "    \n",
    "    # Load up data as dataframe\n",
    "    ratingData = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"C:/My_Data/MS/CS657/HW-4/InputData/ratings.csv\")\n",
    "    ratingData = ratingData.limit(500)\n",
    "    ratingData.show(20)\n",
    "    \n",
    "    moviesData = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"C:/My_Data/MS/CS657/HW-4/InputData/movies.csv\")\n",
    "    moviesData.limit(1000)\n",
    "    #moviesData.show(20)\n",
    "        \n",
    "    ########################## ALS Model ############################################################################\n",
    "    \n",
    "#     train_data,test_data = ratingData.randomSplit([0.8,0.2])\n",
    "    \n",
    "#     recommender = ALS(maxIter = 5, nonnegative = True,implicitPrefs = False,coldStartStrategy=\"drop\", \n",
    "#                       userCol='userId', itemCol='movieId', ratingCol='rating')\n",
    "    \n",
    "    \n",
    "#     param_grid = ParamGridBuilder().addGrid(recommender.rank, [5, 10, 15]).addGrid(recommender.regParam, [.01]).build()\n",
    "    \n",
    "#     evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\") \n",
    "    \n",
    "#     cv = CrossValidator(estimator=recommender, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
    "    \n",
    "#     model = cv.fit(train_data)\n",
    "#     model = model.bestModel\n",
    "#     pred_data = model.transform(test_data)\n",
    "#     pred_data.show()\n",
    "    ########################################################################################################################\n",
    "    \n",
    "    \n",
    "    ########################## RMSE , MSE and MAP for ALS  ####################################################################\n",
    "    \n",
    "#     RMSE = evaluator.evaluate(pred_data)\n",
    "#     print(\"RMSE = %s\" % RMSE)\n",
    "#     MSE = evaluator.evaluate(pred_data, {evaluator.metricName: \"mse\"})\n",
    "#     # Mean absolute error\n",
    "#     print(\"MAE = %s\" % MSE)\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    \n",
    "    ########################## View reommendations in interpretable format for ALS  #################################################################\n",
    "#     recommendations = model.recommendForAllUsers(5)\n",
    "#     recommendations.show()\n",
    "    \n",
    "#     recomentdationFormatted = recommendations.withColumn(\"recommendFormat\", explode(\"recommendations\")).select('userId', col(\"recommendFormat.movieId\"), col(\"recommendFormat.rating\"))\n",
    "#     recomentdationFormatted.limit(10).show()\n",
    "    \n",
    "#     recomentdationFormatted.join(moviesData, on='movieId').filter('userId = 1').show()\n",
    "    \n",
    "#     ratingData.join(moviesData, on='movieId').filter('userId = 1').sort('rating', ascending=False).limit(10).show()\n",
    "    ########################################################################################################################\n",
    "    \n",
    "    \n",
    "    ########################## Collaborative item-item  filtering ##############################################################\n",
    "    \n",
    "    # Map ratings to key / value pairs: user ID => movie ID, rating\n",
    "    data = spark.textFile(\"C:/My_Data/MS/CS657/HW-4/InputData/ratings.csv\")\n",
    "    # print(data.collect())\n",
    "    ratings = data.map(lambda l: l.split(\"::\")).map(lambda l: (int(l[0]), (int(l[1]), float(l[2]))))\n",
    "\n",
    "    print(ratings.collect())\n",
    "    \n",
    "    \n",
    "    ########################################################################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
