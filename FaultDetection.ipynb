{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession, SQLContext, Row\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import col, mean, monotonically_increasing_id, floor\n",
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler,IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier, GBTClassifier, NaiveBayes, LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8712, 6)\n",
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|[6.6541875,15.337...|\n",
      "|       0.0|         0.0|[-18.8354625,-17....|\n",
      "|       0.0|         0.0|[12.9744125,2.229...|\n",
      "|       0.0|         0.0|[6.224725,14.8163...|\n",
      "|       0.0|         0.0|[-18.17825,-16.41...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "0.9367771781033153\n",
      "Test Error = 0.0632228 \n",
      "+--------------+------+--------------------+\n",
      "|predictedLabel|target|            features|\n",
      "+--------------+------+--------------------+\n",
      "|             0|     0|[16.57915,12.3528...|\n",
      "|             0|     0|[-12.6643875,-21....|\n",
      "|             0|     0|[-5.0177,-13.7787...|\n",
      "|             0|     0|[18.4826,17.15638...|\n",
      "|             0|     0|[-19.593375,-17.6...|\n",
      "+--------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "0.9430955993930197\n",
      "Test Error = 0.0569044\n",
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|[16.57915,12.3528...|\n",
      "|       0.0|         0.0|[-12.6643875,-21....|\n",
      "|       0.0|         0.0|[-5.0177,-13.7787...|\n",
      "|       0.0|         0.0|[18.4826,17.15638...|\n",
      "|       0.0|         0.0|[-19.593375,-17.6...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "0.9427162367223065\n",
      "Test Error = 0.0572838\n",
      "+--------------------+------+----------+\n",
      "|            features|target|prediction|\n",
      "+--------------------+------+----------+\n",
      "|[16.57915,12.3528...|     0|       0.0|\n",
      "|[-12.6643875,-21....|     0|       0.0|\n",
      "|[-5.0177,-13.7787...|     0|       0.0|\n",
      "|[18.4826,17.15638...|     0|       0.0|\n",
      "|[-19.593375,-17.6...|     0|       0.0|\n",
      "|[-2.3339125,-15.7...|     0|       0.0|\n",
      "|[-15.605475,-5.14...|     0|       0.0|\n",
      "|[3.5305375,-8.470...|     0|       0.0|\n",
      "|[-19.5504,-18.901...|     0|       0.0|\n",
      "|[6.62035,15.09233...|     0|       0.0|\n",
      "+--------------------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Test accuracy = 0.943096\n",
      "+--------------+------+--------------------+\n",
      "|predictedLabel|target|     features_hybrid|\n",
      "+--------------+------+--------------------+\n",
      "|             0|     0|[10.809125,0.5727...|\n",
      "|             0|     1|[-9.6913125,1.001...|\n",
      "|             0|     1|[-9.7676625,-16.9...|\n",
      "|             0|     1|[18.48585,15.1597...|\n",
      "|             0|     0|[-19.958425,-19.1...|\n",
      "+--------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "0.948041876696394\n",
      "Test Error = 0.0519581\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create a SparkSession (Note, the config section is only for Windows!)\n",
    "    spark = SparkSession.builder.master('local[*]').config('spark.executor.memory', '12g').config('spark.driver.memory', '12g').config('spark.driver.maxResultSize', '12g').config(\"spark.cores.max\", \"6\").appName(\"FaultDetection\").getOrCreate()\n",
    "    #spark = SparkSession.builder.appName(\"RecommenderSystem\").getOrCreate()\n",
    "    \n",
    "    # Load up data as dataframe\n",
    "    data = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"C:/My_Data/MS/CS657/Project/InputData/metadata_train.csv\")\n",
    "    \n",
    "    signalData = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").parquet(\"C:/My_Data/MS/CS657/Project/InputData/train.parquet\")\n",
    "    \n",
    "    \n",
    "    ################################# Decision Tree Classifier #######################################################\n",
    "    \n",
    "    featureData = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").parquet(\"C:/My_Data/MS/CS657/Project/InputData/featuresData/finalfeatures.parquet\")\n",
    "    finalData = data.join(featureData,data.signal_id ==  featureData.signal_id,\"inner\")\n",
    "    #finalData.show(1000)\n",
    "    print((finalData.count(), len(finalData.columns)))\n",
    "    # Index labels, adding metadata to the label column.\n",
    "    # Fit on whole dataset to include all labels in index.\n",
    "    labelIndexer = StringIndexer(inputCol=\"target\", outputCol=\"indexedLabel\").fit(finalData)\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=10).fit(finalData)\n",
    "\n",
    "    # Split the data into training and test sets (30% held out for testing)\n",
    "    (trainingData, testData) = finalData.randomSplit([0.7, 0.3])\n",
    "\n",
    "    # Train a DecisionTree model.\n",
    "    dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "    # Chain indexers and tree in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    model = pipeline.fit(trainingData)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(accuracy)\n",
    "    print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    \n",
    "    ################################# Random Forest Classifier #######################################################\n",
    "    \n",
    "    # Index labels, adding metadata to the label column.\n",
    "    # Fit on whole dataset to include all labels in index.\n",
    "    labelIndexer = StringIndexer(inputCol=\"target\", outputCol=\"indexedLabel\").fit(finalData)\n",
    "\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(finalData)\n",
    "\n",
    "    # Split the data into training and test sets (30% held out for testing)\n",
    "    (trainingData, testData) = finalData.randomSplit([0.7, 0.3])\n",
    "    \n",
    "    # Train a RandomForest model.\n",
    "    rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=5)\n",
    "\n",
    "    # Convert indexed labels back to original labels.\n",
    "    labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                                   labels=labelIndexer.labels)\n",
    "\n",
    "    # Chain indexers and forest in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    model = pipeline.fit(trainingData)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"predictedLabel\", \"target\", \"features\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(accuracy)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    \n",
    "    ################################# Gradient-boosted tree Classifier #######################################################\n",
    "    \n",
    "    # Train a GBT model.\n",
    "    gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=5)\n",
    "\n",
    "    # Chain indexers and GBT in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    model = pipeline.fit(trainingData)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(accuracy)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    \n",
    "    ################################# Linear SVM Classifier ###############################################\n",
    "    \n",
    "    lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"target\")\n",
    "    \n",
    "    # Fit the model\n",
    "    lsvcModel = lsvc.fit(trainingData)\n",
    "    # Compute predictions for test data\n",
    "    predictions = lsvcModel.transform(testData)\n",
    "\n",
    "    # Show the computed predictions and compare with the original labels\n",
    "    predictions.select(\"features\", \"target\", \"prediction\").show(10)\n",
    "\n",
    "    # Define the evaluator method with the corresponding metric and compute the classification error on test data\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"target\").setMetricName('accuracy')\n",
    "    accuracy = evaluator.evaluate(predictions) \n",
    "\n",
    "    # Show the accuracy\n",
    "    print(\"Test accuracy = %g\" % (accuracy))\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    \n",
    "    \n",
    "    ################################# Hybrid Random Forest Classifier  ###############################################\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=[\"features\", \"phase\"],outputCol=\"features_hybrid\")\n",
    "\n",
    "    finalData = assembler.transform(finalData)\n",
    "    \n",
    "    # Index labels, adding metadata to the label column.\n",
    "    # Fit on whole dataset to include all labels in index.\n",
    "    labelIndexer = StringIndexer(inputCol=\"target\", outputCol=\"indexedLabel\").fit(finalData)\n",
    "\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(finalData)\n",
    "\n",
    "    # Split the data into training and test sets (30% held out for testing)\n",
    "    (trainingData, testData) = finalData.randomSplit([0.7, 0.3])\n",
    "    \n",
    "     # Train a RandomForest model.\n",
    "    rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=15)\n",
    "\n",
    "    # Convert indexed labels back to original labels.\n",
    "    labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                                   labels=labelIndexer.labels)\n",
    "\n",
    "    # Chain indexers and forest in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    model = pipeline.fit(trainingData)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"predictedLabel\", \"target\", \"features_hybrid\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(accuracy)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    \n",
    "    \n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
