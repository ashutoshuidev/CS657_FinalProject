{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession, SQLContext, Row\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import col, mean, monotonically_increasing_id, floor\n",
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler,IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier, GBTClassifier, LogisticRegression, LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8712, 6)\n",
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|[-19.958425,-19.1...|\n",
      "|       0.0|         0.0|[12.9744125,2.229...|\n",
      "|       0.0|         0.0|[-18.17825,-16.41...|\n",
      "|       0.0|         0.0|[-11.940825,-19.1...|\n",
      "|       0.0|         0.0|[15.329475,7.5545...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "0.9414652567975831\n",
      "Test Error = 0.0585347 \n",
      "+--------------+------+--------------------+\n",
      "|predictedLabel|target|            features|\n",
      "+--------------+------+--------------------+\n",
      "|             0|     0|[-18.8354625,-17....|\n",
      "|             0|     1|[-9.6913125,1.001...|\n",
      "|             0|     0|[6.595825,16.1692...|\n",
      "|             0|     0|[20.193325,13.200...|\n",
      "|             0|     0|[15.329475,7.5545...|\n",
      "+--------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "0.9398821218074657\n",
      "Test Error = 0.0601179\n",
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|[-18.8354625,-17....|\n",
      "|       0.0|         1.0|[-9.6913125,1.001...|\n",
      "|       0.0|         0.0|[6.595825,16.1692...|\n",
      "|       0.0|         0.0|[20.193325,13.200...|\n",
      "|       0.0|         0.0|[15.329475,7.5545...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "0.9383104125736739\n",
      "Test Error = 0.0616896\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PipelineModel' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-56b1a7ca63df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Error = %g\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[0mfpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FPR'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m     \u001b[0mtpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TPR'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PipelineModel' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create a SparkSession (Note, the config section is only for Windows!)\n",
    "    spark = SparkSession.builder.master('local[*]').config('spark.executor.memory', '12g').config('spark.driver.memory', '12g').config('spark.driver.maxResultSize', '12g').config(\"spark.cores.max\", \"6\").appName(\"FaultDetection\").getOrCreate()\n",
    "    #spark = SparkSession.builder.appName(\"RecommenderSystem\").getOrCreate()\n",
    "    \n",
    "    # Load up data as dataframe\n",
    "    data = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"C:/My_Data/MS/CS657/Project/InputData/metadata_train.csv\")\n",
    "    \n",
    "    signalData = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").parquet(\"C:/My_Data/MS/CS657/Project/InputData/train.parquet\")\n",
    "    \n",
    "    \n",
    "    ################################# Decision Tree Classifier #######################################################\n",
    "    \n",
    "    featureData = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").parquet(\"C:/My_Data/MS/CS657/Project/InputData/featuresData/finalfeatures.parquet\")\n",
    "    finalData = data.join(featureData,data.signal_id ==  featureData.signal_id,\"inner\")\n",
    "    #finalData.show(1000)\n",
    "    print((finalData.count(), len(finalData.columns)))\n",
    "    # Index labels, adding metadata to the label column.\n",
    "    # Fit on whole dataset to include all labels in index.\n",
    "    labelIndexer = StringIndexer(inputCol=\"target\", outputCol=\"indexedLabel\").fit(finalData)\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=10).fit(finalData)\n",
    "\n",
    "    # Split the data into training and test sets (30% held out for testing)\n",
    "    (trainingData, testData) = finalData.randomSplit([0.7, 0.3])\n",
    "\n",
    "    # Train a DecisionTree model.\n",
    "    dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "    # Chain indexers and tree in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    model = pipeline.fit(trainingData)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(accuracy)\n",
    "    print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    \n",
    "    ################################# Random Forest Classifier #######################################################\n",
    "    \n",
    "    # Index labels, adding metadata to the label column.\n",
    "    # Fit on whole dataset to include all labels in index.\n",
    "    labelIndexer = StringIndexer(inputCol=\"target\", outputCol=\"indexedLabel\").fit(finalData)\n",
    "\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(finalData)\n",
    "\n",
    "    # Split the data into training and test sets (30% held out for testing)\n",
    "    (trainingData, testData) = finalData.randomSplit([0.7, 0.3])\n",
    "    \n",
    "    # Train a RandomForest model.\n",
    "    rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=5)\n",
    "\n",
    "    # Convert indexed labels back to original labels.\n",
    "    labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                                   labels=labelIndexer.labels)\n",
    "\n",
    "    # Chain indexers and forest in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    model = pipeline.fit(trainingData)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"predictedLabel\", \"target\", \"features\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(accuracy)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    \n",
    "    ################################# Gradient-boosted tree Classifier #######################################################\n",
    "    \n",
    "    # Train a GBT model.\n",
    "    gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=5)\n",
    "\n",
    "    # Chain indexers and GBT in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    model = pipeline.fit(trainingData)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(accuracy)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    \n",
    "    ################################# Linear SVM Classifier ###############################################\n",
    "    \n",
    "    lsvc = LinearSVC(maxIter=10, regParam=0.5, labelCol=\"target\")\n",
    "    \n",
    "    # Fit the model\n",
    "    lsvcModel = lsvc.fit(trainingData)\n",
    "    # Compute predictions for test data\n",
    "    predictions = lsvcModel.transform(testData)\n",
    "\n",
    "    # Show the computed predictions and compare with the original labels\n",
    "    predictions.select(\"features\", \"target\", \"prediction\").show(10)\n",
    "\n",
    "    # Define the evaluator method with the corresponding metric and compute the classification error on test data\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"target\").setMetricName('accuracy')\n",
    "    accuracy = evaluator.evaluate(predictions) \n",
    "\n",
    "    # Show the accuracy\n",
    "    print(\"Test accuracy = %g\" % (accuracy))\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    \n",
    "    \n",
    "    ################################# Hybrid Random Forest Classifier  ###############################################\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=[\"features\", \"phase\"],outputCol=\"features_hybrid\")\n",
    "\n",
    "    finalData = assembler.transform(finalData)\n",
    "    \n",
    "    # Index labels, adding metadata to the label column.\n",
    "    # Fit on whole dataset to include all labels in index.\n",
    "    labelIndexer = StringIndexer(inputCol=\"target\", outputCol=\"indexedLabel\").fit(finalData)\n",
    "\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(finalData)\n",
    "\n",
    "    # Split the data into training and test sets (30% held out for testing)\n",
    "    (trainingData, testData) = finalData.randomSplit([0.7, 0.3])\n",
    "    \n",
    "     # Train a RandomForest model.\n",
    "    rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=15)\n",
    "\n",
    "    # Convert indexed labels back to original labels.\n",
    "    labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                                   labels=labelIndexer.labels)\n",
    "\n",
    "    # Chain indexers and forest in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    model = pipeline.fit(trainingData)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"predictedLabel\", \"target\", \"features_hybrid\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(accuracy)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    \n",
    "    ################################# logistic Regression Classifier  ###############################################\n",
    "    \n",
    "    # Train a DecisionTree model.\n",
    "    lr = LogisticRegression(labelCol=\"target\",regParam = 0.5, maxIter=100)\n",
    "\n",
    "    # Fit the model\n",
    "    lrModel = lr.fit(trainingData)\n",
    "\n",
    "    # Compute predictions for test data\n",
    "    predictions = lrModel.transform(testData)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"features\", \"target\", \"prediction\").show(10)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(accuracy)\n",
    "    print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "    fpr = lrModel.summary.roc.select('FPR').collect()\n",
    "    tpr = lrModel.summary.roc.select('TPR').collect()\n",
    "\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "    \n",
    "    #################################################################################################################\n",
    "    \n",
    "    \n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
